{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# (25, 4) 크기의 csv 파일을 불러오기\n",
    "loaded_data = np.loadtxt('C:/Users/user/MLworkspace/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[:, 0:-1]\n",
    "t_data = loaded_data[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) (25, 1)\n",
      "(3, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, t_data.shape)\n",
    "\n",
    "W = np.random.rand(3, 1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(W.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "\n",
    "    return ( np.sum((t-y)**2) ) / (len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "\n",
    "    return ( np.sum((t-y)**2) ) / (len(x))\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  3028.617244781001 \n",
      "Initial W =  [[0.58403852]\n",
      " [0.49332542]\n",
      " [0.26347685]] \n",
      "Initial b =  [0.88787854]\n",
      "step =  0 error value =  1130.9114580992207 W =  [[0.67160404]\n",
      " [0.58136254]\n",
      " [0.35393917]] b =  [0.888539]\n",
      "step =  400 error value =  14.640217656397727 W =  [[0.76298122]\n",
      " [0.67180488]\n",
      " [0.58259403]] b =  [0.88945266]\n",
      "step =  800 error value =  12.460329664430084 W =  [[0.72284954]\n",
      " [0.6344748 ]\n",
      " [0.65807817]] b =  [0.88924399]\n",
      "step =  1200 error value =  10.873613615610978 W =  [[0.68676645]\n",
      " [0.60454713]\n",
      " [0.72239494]] b =  [0.88895225]\n",
      "step =  1600 error value =  9.713260367737988 W =  [[0.65430916]\n",
      " [0.58069025]\n",
      " [0.77725637]] b =  [0.88858965]\n",
      "step =  2000 error value =  8.860443929215817 W =  [[0.62510125]\n",
      " [0.56180145]\n",
      " [0.82410575]] b =  [0.88816652]\n",
      "step =  2400 error value =  8.230311874951177 W =  [[0.59880723]\n",
      " [0.54696848]\n",
      " [0.86416046]] b =  [0.88769163]\n",
      "step =  2800 error value =  7.76210516669509 W =  [[0.57512782]\n",
      " [0.53543752]\n",
      " [0.89844793]] b =  [0.88717244]\n",
      "step =  3200 error value =  7.412182960414312 W =  [[0.55379582]\n",
      " [0.52658639]\n",
      " [0.92783574]] b =  [0.88661528]\n",
      "step =  3600 error value =  7.149092371872453 W =  [[0.53457246]\n",
      " [0.51990231]\n",
      " [0.95305698]] b =  [0.88602553]\n",
      "step =  4000 error value =  6.950078873507863 W =  [[0.51724421]\n",
      " [0.51496329]\n",
      " [0.97473151]] b =  [0.88540777]\n",
      "step =  4400 error value =  6.798612473528696 W =  [[0.50161994]\n",
      " [0.51142263]\n",
      " [0.99338379]] b =  [0.88476592]\n",
      "step =  4800 error value =  6.682630840470422 W =  [[0.4875285 ]\n",
      " [0.50899606]\n",
      " [1.00945793]] b =  [0.88410331]\n",
      "step =  5200 error value =  6.593289040074853 W =  [[0.47481648]\n",
      " [0.50745102]\n",
      " [1.02333026]] b =  [0.88342279]\n",
      "step =  5600 error value =  6.524067735361079 W =  [[0.46334631]\n",
      " [0.50659766]\n",
      " [1.03531995]] b =  [0.88272681]\n",
      "step =  6000 error value =  6.470135412044365 W =  [[0.45299453]\n",
      " [0.50628147]\n",
      " [1.04569795]] b =  [0.88201745]\n",
      "step =  6400 error value =  6.427890933828184 W =  [[0.44365031]\n",
      " [0.5063771 ]\n",
      " [1.05469446]] b =  [0.8812965]\n",
      "step =  6800 error value =  6.394634366579096 W =  [[0.43521407]\n",
      " [0.50678321]\n",
      " [1.06250524]] b =  [0.8805655]\n",
      "step =  7200 error value =  6.368329246130676 W =  [[0.42759632]\n",
      " [0.50741825]\n",
      " [1.06929697]] b =  [0.87982578]\n",
      "step =  7600 error value =  6.347430202776319 W =  [[0.4207166 ]\n",
      " [0.50821687]\n",
      " [1.07521168]] b =  [0.87907847]\n",
      "step =  8000 error value =  6.330757431153767 W =  [[0.41450251]\n",
      " [0.50912705]\n",
      " [1.08037053]] b =  [0.87832456]\n",
      "step =  8400 error value =  6.3174048445082205 W =  [[0.40888891]\n",
      " [0.51010768]\n",
      " [1.08487704]] b =  [0.87756489]\n",
      "step =  8800 error value =  6.306672535686284 W =  [[0.40381715]\n",
      " [0.51112649]\n",
      " [1.0888197 ]] b =  [0.8768002]\n",
      "step =  9200 error value =  6.298016846418718 W =  [[0.39923439]\n",
      " [0.51215847]\n",
      " [1.09227429]] b =  [0.87603113]\n",
      "step =  9600 error value =  6.291013246856657 W =  [[0.39509307]\n",
      " [0.51318448]\n",
      " [1.09530577]] b =  [0.87525822]\n",
      "step =  10000 error value =  6.285328577858304 W =  [[0.39135028]\n",
      " [0.51419009]\n",
      " [1.09796989]] b =  [0.87448195]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"\\nInitial W = \", W, \"\\nInitial b = \", b)\n",
    "\n",
    "for step in range(10001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "\n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \"b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.33569933]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "print(predict(test_data))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}