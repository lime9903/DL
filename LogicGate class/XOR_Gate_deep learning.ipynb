{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External function\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "def sigmoid(z):\r\n",
    "    return 1 / (1 + np.exp(-z))\r\n",
    "\r\n",
    "def num_der(f, x):\r\n",
    "    delta_x = 1e-4\r\n",
    "    grad = np.zeros_like(x)\r\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\r\n",
    "\r\n",
    "    while not it.finished:\r\n",
    "        idx = it.multi_index\r\n",
    "        tmp_val = x[idx]\r\n",
    "\r\n",
    "        x[idx] = float(tmp_val) + delta_x\r\n",
    "        fx1 = f(x)\r\n",
    "\r\n",
    "        x[idx] = tmp_val - delta_x\r\n",
    "        fx2 = f(x)\r\n",
    "\r\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\r\n",
    "        x[idx] = tmp_val\r\n",
    "        it.iternext()\r\n",
    "    \r\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogicGate Class\r\n",
    "class LogicGate:\r\n",
    "    \r\n",
    "    def __init__(self, gate_name, xdata, tdata):\r\n",
    "        self.name = gate_name\r\n",
    "        \r\n",
    "        # 입력과 출력 데이터 크기 조정\r\n",
    "        self.__xdata = xdata.reshape(4, 2)\r\n",
    "        self.__tdata = tdata.reshape(4, 1)\r\n",
    "\r\n",
    "        # 입력층-은닉층의 가중치와 바이어스 초기화\r\n",
    "        # 6개의 노드로 가정하였다.\r\n",
    "        self.__W2 = np.random.rand(2, 6)\r\n",
    "        self.__b2 = np.random.rand(6)\r\n",
    "\r\n",
    "        # 은닉층-출력층의 가중치와 바이어스 초기화\r\n",
    "        self.__W3 = np.random.rand(6, 1)\r\n",
    "        self.__b3 = np.random.rand(1)\r\n",
    "\r\n",
    "        # 학습률 초기화\r\n",
    "        self.learning_rate = 1e-2\r\n",
    "\r\n",
    "        print(\"\\n\" + self.name + \" object is created!\\n\")\r\n",
    "\r\n",
    "    def feed_forword(self):\r\n",
    "        delta = 1e-7  # 무한대 발산 방지\r\n",
    "\r\n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\r\n",
    "        a2 = sigmoid(z2)\r\n",
    "\r\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\r\n",
    "        y = a3 = sigmoid(z3)\r\n",
    "\r\n",
    "        return -np.sum( self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta) )\r\n",
    "\r\n",
    "    \r\n",
    "    def loss_val(self):\r\n",
    "        delta = 1e-7\r\n",
    "\r\n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\r\n",
    "        a2 = sigmoid(z2)\r\n",
    "\r\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\r\n",
    "        y = a3 = sigmoid(z3)\r\n",
    "\r\n",
    "        return -np.sum( self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta) )\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        f = lambda x : self.feed_forword()\r\n",
    "\r\n",
    "        print(\"Initial loss value = \" , self.loss_val())\r\n",
    "\r\n",
    "        for step in range(10001):\r\n",
    "\r\n",
    "            self.__W2 -= self.learning_rate * num_der(f, self.__W2)\r\n",
    "            self.__b2 -= self.learning_rate * num_der(f, self.__b2)\r\n",
    "            self.__W3 -= self.learning_rate * num_der(f, self.__W3)\r\n",
    "            self.__b3 -= self.learning_rate * num_der(f, self.__b3)\r\n",
    "\r\n",
    "            if (step % 1000 == 0):\r\n",
    "                print(\"step = \", step, \"  loss value = \", self.loss_val())\r\n",
    "\r\n",
    "    def predict(self, xdata):\r\n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2\r\n",
    "        a2 = sigmoid(z2)\r\n",
    "\r\n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\r\n",
    "        y = sigmoid(z3)\r\n",
    "\r\n",
    "        if y > 0.5:\r\n",
    "            result = 1\r\n",
    "        else:\r\n",
    "            result = 0\r\n",
    "        \r\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND_GATE object is created!\n",
      "\n",
      "Initial loss value =  6.351847171020783\n",
      "step =  0   loss value =  6.095722954335691\n",
      "step =  1000   loss value =  1.8104469183365102\n",
      "step =  2000   loss value =  0.9076065588470372\n",
      "step =  3000   loss value =  0.42736684055714014\n",
      "step =  4000   loss value =  0.23113030523946865\n",
      "step =  5000   loss value =  0.14525194077794842\n",
      "step =  6000   loss value =  0.10156491594687483\n",
      "step =  7000   loss value =  0.07632583687308526\n",
      "step =  8000   loss value =  0.06030164912965123\n",
      "step =  9000   loss value =  0.04939399070568784\n",
      "step =  10000   loss value =  0.04156860151372238\n",
      "(array([4.69241903e-05]), 0)\n",
      "(array([0.01018737]), 0)\n",
      "(array([0.01047066]), 0)\n",
      "(array([0.97945733]), 1)\n",
      "\n",
      "OR_GATE object is created!\n",
      "\n",
      "Initial loss value =  2.2726112403794763\n",
      "step =  0   loss value =  2.2666958453780706\n",
      "step =  1000   loss value =  1.6892564756758655\n",
      "step =  2000   loss value =  0.8685102505227316\n",
      "step =  3000   loss value =  0.3959125647526865\n",
      "step =  4000   loss value =  0.21643111733279355\n",
      "step =  5000   loss value =  0.13875877028580455\n",
      "step =  6000   loss value =  0.09861289686329755\n",
      "step =  7000   loss value =  0.07497606259076474\n",
      "step =  8000   loss value =  0.05972179023497971\n",
      "step =  9000   loss value =  0.04920096966814359\n",
      "step =  10000   loss value =  0.04157435810474137\n",
      "(array([0.02357927]), 0)\n",
      "(array([0.99206086]), 1)\n",
      "(array([0.99092158]), 1)\n",
      "(array([0.99937785]), 1)\n",
      "\n",
      "NAND_GATE object is created!\n",
      "\n",
      "Initial loss value =  3.6882787528007315\n",
      "step =  0   loss value =  3.6512004583555213\n",
      "step =  1000   loss value =  1.9401041391165945\n",
      "step =  2000   loss value =  1.0998859685089963\n",
      "step =  3000   loss value =  0.5333216285599425\n",
      "step =  4000   loss value =  0.28167479675624324\n",
      "step =  5000   loss value =  0.17283160715616047\n",
      "step =  6000   loss value =  0.11876063585863178\n",
      "step =  7000   loss value =  0.0881319620626223\n",
      "step =  8000   loss value =  0.06897817680952291\n",
      "step =  9000   loss value =  0.05609267185232133\n",
      "step =  10000   loss value =  0.04693445955791605\n",
      "(array([0.99993247]), 1)\n",
      "(array([0.98827435]), 1)\n",
      "(array([0.98887928]), 1)\n",
      "(array([0.02360629]), 0)\n",
      "\n",
      "XOR_GATE object is created!\n",
      "\n",
      "Initial loss value =  6.551817833807634\n",
      "step =  0   loss value =  6.40994504373389\n",
      "step =  1000   loss value =  2.766099914481106\n",
      "step =  2000   loss value =  2.741099477637789\n",
      "step =  3000   loss value =  2.672481654788891\n",
      "step =  4000   loss value =  2.52076785239003\n",
      "step =  5000   loss value =  2.2908787213089514\n",
      "step =  6000   loss value =  2.0515364456450444\n",
      "step =  7000   loss value =  1.8092007758133195\n",
      "step =  8000   loss value =  1.5160926401898283\n",
      "step =  9000   loss value =  1.170783472145147\n",
      "step =  10000   loss value =  0.8567112602565218\n",
      "(array([0.11614933]), 0)\n",
      "(array([0.81360513]), 1)\n",
      "(array([0.8081393]), 1)\n",
      "(array([0.2694398]), 0)\n"
     ]
    }
   ],
   "source": [
    "# Usage\r\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\r\n",
    "AND_tdata = np.array([0, 0, 0, 1])\r\n",
    "OR_tdata = np.array([0, 1, 1, 1])\r\n",
    "NAND_tdata = np.array([1, 1, 1, 0])\r\n",
    "XOR_tdata = np.array([0, 1, 1, 0])\r\n",
    "\r\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\r\n",
    "\r\n",
    "# AND gate\r\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, AND_tdata)\r\n",
    "AND_obj.train()\r\n",
    "\r\n",
    "for data in test_data:\r\n",
    "    print(AND_obj.predict(data))\r\n",
    "\r\n",
    "# OR gate\r\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, OR_tdata)\r\n",
    "OR_obj.train()\r\n",
    "\r\n",
    "for data in test_data:\r\n",
    "    print(OR_obj.predict(data))\r\n",
    "\r\n",
    "# NAND gate\r\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, NAND_tdata)\r\n",
    "NAND_obj.train()\r\n",
    "\r\n",
    "for data in test_data:\r\n",
    "    print(NAND_obj.predict(data))\r\n",
    "\r\n",
    "# XOR gate\r\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", xdata, XOR_tdata)\r\n",
    "XOR_obj.train()\r\n",
    "\r\n",
    "for data in test_data:\r\n",
    "    print(XOR_obj.predict(data))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}